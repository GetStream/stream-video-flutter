## Building Chat Apps With Video Support

One of the most common chat app use cases is having a chat feature in your app that allows users to engage in audio and video communication. This direct integration allows for simple transition between text and images to more complex media.

Stream supports this use case, out-of-the-box. In this guide, you'll walk through all the steps required to integrate our Chat and Video Android SDKs into a cohesive whole. You'll cover the following:

* Adding Stream dependencies.
* Creating Stream clients.
* Authenticating Chat and Video users.
* Building custom Call attachments and "Start Call" UI.

By the end of this guide, your app will look like this:

![Message List Example]()

You'll have the ability to create messaging conversations, in which you can start calls as a custom attachment. Anyone in the chat will then be notified accordingly and can join the call.

Let's see how to implement this.

## Creating the project

The easiest way to get a project working is using one of our [Starter Kits](https://github.com/GetStream/stream-video-flutter/tree/main/examples/chat_with_video). Within the `chat_with_video` directory, open `chat_with_video_starter` in your IDE.

> **Note**: Within the `chat_with_video` parent, there is a `chat_with_video_final` project that contains the final code for this guide. You can skip the starter kit and open that project instead if you want to see the finished solution.

Run `flutter pub get` to install the dependencies declared in `pubspec.yaml`:

```yaml title="/pubspec.yaml"
dependencies:
  flutter:
    sdk: flutter

  # Stream Chat SDK
  stream_chat_flutter: 5.2.0

  # Stream Video SDK
  stream_video_flutter:
    path: ../../../stream_video_flutter // TODO replace with published dependency
```

You'll be integrating two SDKs - Video and Chat. The file contains corresponding dependencies for each SDK.

The project already has a few screens set up for you with TODO items that you'll fill in later. Run the project and you should see the Login screen, followed by a blank Home screen after you select a user.

| Login Screen | Home Screen |
| ------------ | ----------- |
| ![Login Screen]() | ![Home Screen]() |

The pre-baked code contains all the logic that is not related to Stream, so that you can focus solely on integrating our two SDKs. We recommend exploring the project to learn how to navigate it and what each part of the predefined code does. Some of the notable functionality in the starter kit contains:

// TODO: list of feature of the starter kit

Now that you have an overview of the starter project, let's start integrating the SDKs.

## Integrating the Chat SDK

// TODO: init StreamChatClient

### Creating the Client

Open the `main.dart` file and replace the `StreamChatClient` initialization with the following:

```dart title="/lib/main.dart"
final client = StreamChatClient(
  chatApiKey,
  logLevel: Level.INFO,
);
```

With this client initialization, you can proceed to log in a user when you choose them on the Login screen.

### Logging in a User

Open `choose_user_screen.dart` and replace `_connectChatUser` with the following:

```dart title="/lib/screen/choose_user_screen.dart"
Future<void> _connectChatUser(BuildContext context, SampleUser user) async {
  final chatClient = StreamChat.of(context).client;

  await chatClient.connectUser(
    user.toChatUser(),
    user.chatToken,
  );
}

On the choose user screen, when you select a user, you call `_connectChatUser`. This lets you set up the user for both Chat and Video SDK. In this case, you're doing the following:

1. You create a `User` object that holds the important information, such as the user ID, name and their image.
2. You pass in the `user` to `chatClient.connectUser()`. Aside from that, you provide the `ChatClient` with the user token, that's stored in the `extraData` map of properties. This will initialize the Chat SDK with the provided user and you can proceed to fetch their `Channel`s, `Message`s and more.

To finish up, you can add the logging out counterpart, by going back to `ChatWithVideoApp` and adding the following code to `logOut()`:

```dart
fun logOut() {
    val preferences = UserCredentialsManager.initialize(this)

    // TODO log out of clients
    chatClient.disconnect(true).enqueue() // here
    preferences.clear()
}
```

Using `chatClient.disconnect(flushPersistence = true)`, you prepare a call to disconnect from the SDK and flush any cache. Our functions are wrapped as asynchronous call constructs, so calling `enqueue()` is necessary to start the operation.

With all this, you'll be able to log in and log out any user from our predefined data set. The next step is to display their conversations.

### Implementing Channel List Screen

There isn't much to the `ChannelsActivity` - it'll show a list of `Channel`s the user is a member of and let them open those `Channel`s. It'll also feature a custom header to allow the user to log out at will.

Most of the navigation functionality, like opening a `Channel` and logging out is already there, you just need to use our Compose UI Components to implement the UI.

Open `channel_list_screen.dart`. Add the following code, to initialize the `ChannelListViewModel`, that'll help you load, fetch and display the required data:

```dart
import 'package:chat_with_video_starter/screen/channel_screen.dart';
import 'package:flutter/material.dart';
import 'package:stream_chat_flutter/stream_chat_flutter.dart';
import 'package:stream_video_flutter/stream_video_flutter.dart';

class ChannelListScreen extends StatefulWidget {
  const ChannelListScreen({
    Key? key,
  }) : super(key: key);

  @override
  State<ChannelListScreen> createState() => _ChannelListScreenState();
}

class _ChannelListScreenState extends State<ChannelListScreen> {
  late final _listController = StreamChannelListController(
    client: StreamChat.of(context).client,
    filter: Filter.in_(
      'members',
      [StreamChat.of(context).currentUser!.id],
    ),
    channelStateSort: const [SortOption('last_message_at')],
  );

  @override
  void dispose() {
    _listController.dispose();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    final chatTheme = StreamChatTheme.of(context);
    final textTheme = chatTheme.textTheme;

    return Scaffold(
      appBar: StreamChannelListHeader(
        titleBuilder: (context, status, client) {
          return Text(
            "Chat with Video",
            style: textTheme.headlineBold,
          );
        },
        actions: [
          IconButton(
            icon: const Icon(
              color: Colors.black,
              Icons.logout,
            ),
            onPressed: () async => _logout(context),
          ),
        ],
      ),
      body: StreamChannelListView(
        controller: _listController,
        onChannelTap: (channel) {
          Navigator.of(context).push(
            MaterialPageRoute(
              builder: (context) {
                return StreamChannel(
                  channel: channel,
                  child: ChannelScreen(),
                );
              },
            ),
          );
        },
      ),
    );
  }

  /// Disconnect the currently logged in user from both Video and Chat APIs.
  Future<void> _logout(BuildContext context) async {
    final chatClient = StreamChat.of(context).client;
    await chatClient.disconnectUser();

    final videoClient = StreamVideo.instance;
    await videoClient.disconnectUser();

    Navigator.of(context).pop();
  }
}
```

There are only a few lines of code here that let you set up an entire screen and lots of functionality:
...

Build and run the app and you should be able to log in or out with a user, as well as see and open the `Channel`s they're a part of.

![Screenshot_1673592655]()

The next step to integrating the Chat SDK to replicate a chat-first-app which allows video calls, is to display the selected conversations and integrate custom attachments that render created calls.

### Adding Messaging Functionality

You're able to open the `ChannelScreen`, but it's fully empty at the moment. Let's change that. Open `ChannelScreen` and at the very top of the class, add the following code:

Copy

```dart
import 'dart:math';

import 'package:flutter/material.dart';
import 'package:stream_chat_flutter/stream_chat_flutter.dart';
import 'package:stream_video_flutter/stream_video_flutter.dart';

class ChannelScreen extends StatelessWidget {
  const ChannelScreen({
    Key? key,
  }) : super(key: key);

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: StreamChannelHeader(
        actions: <Widget>[
          IconButton(
            icon: const Icon(
              Icons.call_rounded,
              color: Colors.black,
            ),
            onPressed: () async => _startCall(context),
          ),
        ],
      ),
      body: Column(
        children: <Widget>[
          Expanded(
            child: StreamMessageListView(
              messageBuilder: (context, details, messages, defaultMessage) {
                return defaultMessage.copyWith(
                  customAttachmentBuilders: {
                    'call': (context, message, attachments) {
                      return WrapAttachmentWidget(
                        attachmentWidget: _CallAttachment(
                          message: message,
                          attachment: attachments.first,
                        ),
                        attachmentShape: RoundedRectangleBorder(
                          borderRadius: BorderRadius.circular(12),
                        ),
                      );
                    }
                  },
                );
              },
            ),
          ),
          StreamMessageInput(),
        ],
      ),
    );
  }

  Map<String, AttachmentBuilder>? _customAttachmentBuilders() {
    return null;

    return {
      'call': (context, message, attachments) {
        return WrapAttachmentWidget(
          attachmentWidget: _CallAttachment(
            message: message,
            attachment: attachments.first,
          ),
          attachmentShape: RoundedRectangleBorder(
            borderRadius: BorderRadius.circular(12),
          ),
        );
      }
    };
  }

  /// Creates a new call and sends a message with its metadata to the chat.
  void _startCall(BuildContext context) async {
    final currentUser = StreamChat.of(context).currentUser;
    final channel = StreamChannel.of(context).channel;

    final createCallResult = await StreamVideo.instance.createCall(
      id: 'call${Random().nextInt(10000)}',
      type: "default",
      ringing: false,
    );

    final call = createCallResult.call;
    final users = createCallResult.users;

    channel.sendMessage(
      Message(
        attachments: [
          Attachment(
            type: "call",
            authorName: currentUser?.name ?? "",
            uploadState: UploadState.success(),
            extraData: {
              "callCid": call.callCid,
              "members": users.values.map((e) => e.name).toList(),
            },
          )
        ],
      ),
    );
  }
}

class _CallAttachment extends StatelessWidget {
  const _CallAttachment({
    required this.message,
    required this.attachment,
  });

  /// The message that [attachment] is associated with.
  final Message message;

  /// The call attachment to display.
  final Attachment attachment;

  @override
  Widget build(BuildContext context) {
    final chatTheme = StreamChatTheme.of(context);
    final colorTheme = chatTheme.colorTheme;
    final textTheme = chatTheme.textTheme;

    final cid = attachment.extraData["callCid"] as String;

    return Container(
      constraints: BoxConstraints(
        maxWidth: 256,
        minWidth: 256,
      ),
      decoration: BoxDecoration(
        color: colorTheme.accentInfo,
        borderRadius: BorderRadius.circular(16),
      ),
      child: Padding(
        padding: const EdgeInsets.symmetric(horizontal: 16, vertical: 8),
        child: Row(
          crossAxisAlignment: CrossAxisAlignment.center,
          children: [
            Expanded(
              child: Text(
                "Video Call",
                style: textTheme.bodyBold,
                maxLines: 1,
              ),
            ),
            Material(
              type: MaterialType.transparency,
              child: SizedBox(
                width: 110,
                height: 44,
                child: ElevatedButton.icon(
                  icon: const Icon(
                    Icons.videocam_rounded,
                    color: Colors.black,
                  ),
                  label: Text(
                    "Join",
                    style: textTheme.bodyBold,
                  ),
                  style: ElevatedButton.styleFrom(
                    backgroundColor: Colors.white,
                    shape: RoundedRectangleBorder(
                      borderRadius: BorderRadius.circular(22),
                    ),
                  ),
                  onPressed: () async {
                    final call = await _joinCall(context, cid);

                    Navigator.push(
                      context,
                      MaterialPageRoute(
                        fullscreenDialog: true,
                        builder: (context) {
                          return StreamActiveCall(
                            call: call,
                            onBackPressed: () => _finishCall(context, call),
                            onHangUp: () => _finishCall(context, call),
                          );
                        },
                      ),
                    );
                  },
                ),
              ),
            ),
          ],
        ),
      ),
    );
  }

  /// Joins the call with the give cid.
  Future<Call> _joinCall(BuildContext context, String cid) async {
    final parts = cid.split(':');
    final type = parts[0];
    final id = parts[1];

    final call = await StreamVideo.instance.joinCall(type: type, id: id);
    await call.connect();
    return call;
  }

  Future<void> _finishCall(BuildContext context, Call call) async {
    await call.disconnect();

    Navigator.of(context).pop();
  }
}
```


### Supporting Custom Attachments




## Integrating the Video SDK

To successfully connect to a Call, you need to use its `callCid` to get the detailed information and join it. The internal process to joining a Call has several steps, such as measuring the latency and choosing the best server to connect through, but all you care about now is the trigger to join a Call and show the corresponding UI.

Firstly, you need to initialize the Video client, aptly called `StreamVideo`.

### Initializing StreamVideo

Open `main.dart`. To initialize the client, there's already a predefined function that you need to fill, using the user credentials. Find and replace the `initializeStreamVideo` code with the following:

```dart
/// Initialize Stream Video SDK.
StreamVideo.init(
"us83cfwuhy8n",
logLevel: Level.INFO,
);
```

To further integrate the client into the app, replace the `logOut` function code with the following:


### Logging in a User

For the login aspect of `StreamVideo`, there's not much to think about. The `StreamVideo` client is tied to a user instance. You cannot access any potential Calls or join an audio/video call, unless you're logged in. It's a server requirement and it makes things easy to think about.

To log into `StreamVideo`, you create the `StreamVideo` instance with a user construct. As long as the instance persists, we consider the user to be logged in.

Open the `choose_user_screen.dart` file and replace the `logInToVideo` code with the following:

```dart
/// Connects the current user to the Video API.
Future<void> _connectVideoUser(SampleUser user) async {
    final videoClient = StreamVideo.instance;

    await videoClient.connectUser(
            user.toVideoUser(),
    token: Token(user.videoToken),
    );
}
```

With all of this, your attachments will be able to hit the Video API endpoints to join a call, but there are two small steps to show the appropriate UI and logic. Declaring the Android inputs in the `AndroidManifest.xml` file and allowing users to start new Calls.

### Allowing Users To Start Calls

Open the `channel_screen.dart` and find `_startCall()`. Within it, add the following code:

```dart
  /// Creates a new call and sends a message with its metadata to the chat.
  void _startCall(BuildContext context) async {
    final currentUser = StreamChat.of(context).currentUser;
    final channel = StreamChannel.of(context).channel;

    final createCallResult = await StreamVideo.instance.createCall(
      id: 'call${Random().nextInt(10000)}',
      type: "default",
      ringing: false,
    );

    final call = createCallResult.call;
    final users = createCallResult.users;

    channel.sendMessage(
      Message(
        attachments: [
          Attachment(
            type: "call",
            authorName: currentUser?.name ?? "",
            uploadState: UploadState.success(),
            extraData: {
              "callCid": call.callCid,
              "members": users.values.map((e) => e.name).toList(),
            },
          )
        ],
      ),
    );
  }
}
```

This snippet is larger than the previous integration steps, but it packs a few things to keep in mind when creating a Call:

1. Using coroutines, you're able to `createCall()` by passing in a Call ID, its `type`, if you want to ring anyone in the Call and its `participantIds`. For simplicity, you'll create **meeting calls**, which don't require any initial Participants or ringing.
2. If the API call is successful, you can proceed to build the Call attachment. If the API call fails, you can show custom UI to the user, but in this case we'll just ignore that case.
3. To build the `Attachment`, you use its constructor, which lets you define the type of the `Attachment`, its author and any `extraData` you might need to render the UI. In this case, you pass in the `call.cid`, list of members if you define any and the `callName` used to show the UI in the list.
4. Finally, when the attachment is ready, you can build a new `Message` using the `composerViewModel` and pass in your `customAttachment`. By calling `composerViewModel.sendMessage(newMessage)`, you create a new message in the channel, with the details required to join the Call.

You could've approached this logic differently and shown special dialogs to the user for the call creation, give them more options for customization, like who to invite and similar. But for this basic use case of Chat + Video, you'll just create a simple call that's public in the Channel.

Now, you're fully ready to start and enjoy the Chat + Video experience. Build and run the app, log in and join any call attachment, or create a new call and join like that.

![call](https://user-images.githubusercontent.com/17215808/212706833-56e7f564-ea74-42f6-85dd-a0c174199773.png)

And much more. You've implemented everything you need to achieve a good Chat + Video use case. Now you can focus on exploring more resources to add features to the project.


